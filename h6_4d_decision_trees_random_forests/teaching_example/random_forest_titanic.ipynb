{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import machine learning methods\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve, RocCurveDisplay, f1_score, precision_score, \\\n",
    "                            recall_score, confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_required = True\n",
    "\n",
    "if download_required:\n",
    "\n",
    "    # Download processed data:\n",
    "    address = 'https://raw.githubusercontent.com/MichaelAllen1966/' + \\\n",
    "                '1804_python_healthcare/master/titanic/data/processed_data.csv'\n",
    "\n",
    "    data = pd.read_csv(address)\n",
    "\n",
    "    # Create a data subfolder if one does not already exist\n",
    "    import os\n",
    "    data_directory ='../datasets/'\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    # Save data\n",
    "    data.to_csv(data_directory + 'processed_titanic_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/processed_titanic_data.csv')\n",
    "# Make all data 'float' type\n",
    "data = data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Passengerid (axis=1 indicates we are removing a column rather than a row)\n",
    "# We drop passenger ID as it is not original data\n",
    "# inplace=True means change the dataframe itself - don't create a copy with this column dropped\n",
    "\n",
    "data.drop('PassengerId', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into X (features) and y (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Survived',axis=1) # X = all 'data' except the 'survived' column\n",
    "y = data['Survived'] # y = 'survived' column from 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into training and tets sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "model = model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict training and test set labels\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shorthand below says to check each predicted y value against the actual\n",
    "# y value in the training data.  This gives a list of True and False values\n",
    "# for each prediction, where True indicates the predicted value matches the\n",
    "# actual value.  Then we take the mean of these Boolean values, which gives\n",
    "# us a proportion (where if all values were True, the proportion would be 1.0)\n",
    "# If you want to see why that works, just uncomment the following line of code\n",
    "# to see what y_pred_train == y_train is doing.\n",
    "# print (y_pred_train == y_train)\n",
    "accuracy_train = np.mean(y_pred_train == y_train)\n",
    "accuracy_test = np.mean(y_pred_test == y_test)\n",
    "\n",
    "print (f'Accuracy of predicting training data = {accuracy_train}')\n",
    "print (f'Accuracy of predicting test data = {accuracy_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first ten predicted classes\n",
    "classes = model.predict(X_test)\n",
    "classes[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first ten predicted probabilities\n",
    "probabilities = model.predict_proba(X_test)\n",
    "probabilities[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred_test, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred_test, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred_test, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/40155128/plot-trees-for-a-random-forest-in-python-with-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 5, figsize = (10,2), dpi=900)\n",
    "for index in range(0, 5):\n",
    "    plot_tree(model.estimators_[index],\n",
    "    feature_names=data.drop('Survived',axis=1).columns.tolist(),\n",
    "    class_names=['Died', 'Survived'],\n",
    "                   filled = True,\n",
    "                   ax = axes[index]);\n",
    "\n",
    "    axes[index].set_title('Estimator: ' + str(index), fontsize = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_run(model):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    accuracy_train = np.mean(y_pred_train == y_train)\n",
    "    accuracy_test = np.mean(y_pred_test == y_test)\n",
    "\n",
    "    print (f'Accuracy of predicting training data = {accuracy_train:.3f}')\n",
    "    print (f'Accuracy of predicting test data = {accuracy_test:.3f}')\n",
    "\n",
    "    print(f\"F1 score: no averaging = {[f'{i:.3f}' for i in f1_score(y_test, y_pred_test, average=None)]}\")\n",
    "    print(f\"F1 score: micro = {f1_score(y_test, y_pred_test, average=\"micro\"):.3f}\")\n",
    "    print(f\"F1 score: macro = {f1_score(y_test, y_pred_test, average=\"macro\"):.3f}\")\n",
    "    print(f\"F1 score: weighted = {f1_score(y_test, y_pred_test, average=\"weighted\"):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "train_and_run(model = DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train_and_run(model = RandomForestClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "random_forest_model = random_forest_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred_train_rf = random_forest_model.predict(X_train)\n",
    "y_pred_test_rf = random_forest_model.predict(X_test)\n",
    "\n",
    "roc_curve_rf = RocCurveDisplay.from_estimator(\n",
    "    random_forest_model, X_test, y_test\n",
    ")\n",
    "\n",
    "confusion_matrix_rf = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix(\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred_test_rf\n",
    "        ),\n",
    "        display_labels=[\"Died\", \"Survived\"]\n",
    ")\n",
    "\n",
    "confusion_matrix_rf_normalised = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix(\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred_test_rf,\n",
    "        normalize='true'\n",
    "        ),\n",
    "        display_labels=[\"Died\", \"Survived\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "decision_tree_model = DecisionTreeClassifier(max_depth=6)\n",
    "decision_tree_model = decision_tree_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred_train_dt = decision_tree_model.predict(X_train)\n",
    "y_pred_test_dt = decision_tree_model.predict(X_test)\n",
    "\n",
    "roc_curve_dt = RocCurveDisplay.from_estimator(\n",
    "    decision_tree_model, X_test, y_test\n",
    ")\n",
    "\n",
    "confusion_matrix_dt = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix(\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred_test_dt\n",
    "        ),\n",
    "        display_labels=[\"Died\", \"Survived\"]\n",
    ")\n",
    "\n",
    "confusion_matrix_dt_normalised = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix(\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred_test_dt,\n",
    "        normalize='true'\n",
    "        ),\n",
    "        display_labels=[\"Died\", \"Survived\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def standardise_data(X_train, X_test):\n",
    "\n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Apply the scaler to the training and test sets\n",
    "    train_std=sc.fit_transform(X_train)\n",
    "    test_std=sc.fit_transform(X_test)\n",
    "\n",
    "    return train_std, test_std\n",
    "\n",
    "X_train_standardised, X_test_standardised = standardise_data(X_train, X_test)\n",
    "\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train_standardised,y_train)\n",
    "\n",
    "y_pred_train_lr = logistic_regression_model.predict(X_train_standardised)\n",
    "y_pred_test_lr = logistic_regression_model.predict(X_test_standardised)\n",
    "\n",
    "roc_curve_lr = RocCurveDisplay.from_estimator(\n",
    "    logistic_regression_model, X_test_standardised, y_test\n",
    ")\n",
    "\n",
    "confusion_matrix_lr = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix(\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred_test_lr\n",
    "        ),\n",
    "        display_labels=[\"Died\", \"Survived\"]\n",
    ")\n",
    "\n",
    "confusion_matrix_lr_normalised = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix(\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred_test_lr,\n",
    "        normalize='true'\n",
    "        ),\n",
    "        display_labels=[\"Died\", \"Survived\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(14, 5))\n",
    "confusion_matrix_rf.plot(ax=ax1)\n",
    "ax1.title.set_text('Random Forest')\n",
    "\n",
    "confusion_matrix_dt.plot(ax=ax2)\n",
    "ax2.title.set_text('Decision Tree')\n",
    "\n",
    "confusion_matrix_lr.plot(ax=ax3)\n",
    "ax3.title.set_text('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(14, 5))\n",
    "confusion_matrix_rf_normalised.plot(ax=ax1)\n",
    "ax1.title.set_text('Random Forest - Normalised')\n",
    "\n",
    "confusion_matrix_dt_normalised.plot(ax=ax2)\n",
    "ax2.title.set_text('Decision Tree - Normalised')\n",
    "\n",
    "confusion_matrix_lr_normalised.plot(ax=ax3)\n",
    "ax3.title.set_text('Logistic Regression - Normalised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "roc_curve_rf.plot(ax=ax1)\n",
    "ax1.title.set_text('Random Forest')\n",
    "ax1.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "\n",
    "roc_curve_dt.plot(ax=ax2)\n",
    "ax2.title.set_text('Decision Tree')\n",
    "ax2.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "\n",
    "roc_curve_lr.plot(ax=ax3)\n",
    "ax3.title.set_text('Logistic Regression')\n",
    "ax3.plot([0, 1], [0, 1], color='darkblue', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n estimators (trees per forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_results = []\n",
    "\n",
    "for i in range(10, 500, 10):\n",
    "    model = model = RandomForestClassifier(n_estimators=i, random_state=42)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    accuracy_train = np.mean(y_pred_train == y_train)\n",
    "    accuracy_test = np.mean(y_pred_test == y_test)\n",
    "    accuracy_results.append({'accuracy_train': accuracy_train, 'accuracy_test': accuracy_test, 'n_estimators': i})\n",
    "\n",
    "px.line(pd.DataFrame(accuracy_results).melt(id_vars='n_estimators'),\n",
    "        x='n_estimators', y='value', color='variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(accuracy_results).set_index(\"n_estimators\").sort_values(by=[\"accuracy_test\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n estimators (trees per forest) - with max depth of 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_results = []\n",
    "\n",
    "for i in range(10, 200, 10):\n",
    "    model = RandomForestClassifier(n_estimators=i, random_state=42, max_depth=8)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    accuracy_train = np.mean(y_pred_train == y_train)\n",
    "    accuracy_test = np.mean(y_pred_test == y_test)\n",
    "    accuracy_results.append({'accuracy_train': accuracy_train, 'accuracy_test': accuracy_test, 'n_estimators': i})\n",
    "\n",
    "px.line(pd.DataFrame(accuracy_results).melt(id_vars='n_estimators'),\n",
    "        x='n_estimators', y='value', color='variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(accuracy_results).set_index(\"n_estimators\").sort_values(by=[\"accuracy_test\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "best_n_estimators = pd.DataFrame(accuracy_results).sort_values(by=[\"accuracy_test\"], ascending=False).head(1)['n_estimators'].values[0]\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=best_n_estimators, random_state=42, max_depth=8)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "roc_curve = RocCurveDisplay.from_estimator(\n",
    "    model, X_test, y_test\n",
    ")\n",
    "\n",
    "fig = roc_curve.figure_\n",
    "ax = roc_curve.ax_\n",
    "\n",
    "\n",
    "ax.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix(\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred_test\n",
    "        ),\n",
    "        display_labels=[\"Died\", \"Survived\"]\n",
    ").plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix(\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred_test,\n",
    "        normalize='true'\n",
    "        ),\n",
    "        display_labels=[\"Died\", \"Survived\"]\n",
    ").plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
