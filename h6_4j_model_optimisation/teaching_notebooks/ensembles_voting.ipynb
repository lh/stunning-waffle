{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn allows you to easily create ensembles of multiple models.\n",
    "\n",
    "We will just be looking at 'voting' classifiers today. These allow you to combine 'conceptually different machine learning classifiers', so are very flexible.\n",
    "\n",
    "You may also want to look into stacking models if this is an area you are interested in exploring further. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main new import is `VotingClassifier` from the `sklearn.ensemble` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model setup imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# NEW IMPORT - VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Scoring models\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, f1_score, precision_score, \\\n",
    "                            recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import our processed titanic dataset and split it into train, validation and testing datsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Samples: 569\n",
      "Validation Dataset Samples: 143\n",
      "Testing Dataset Samples: 179\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_csv(\"data/processed_data.csv\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # Download processed data:\n",
    "    address = 'https://raw.githubusercontent.com/MichaelAllen1966/' + \\\n",
    "                '1804_python_healthcare/master/titanic/data/processed_data.csv'\n",
    "\n",
    "    data = pd.read_csv(address)\n",
    "\n",
    "    # Create a data subfolder if one does not already exist\n",
    "    import os\n",
    "    data_directory ='./data/'\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    # Save data\n",
    "    data.to_csv(data_directory + 'processed_data.csv', index=False)\n",
    "\n",
    "data = data.astype(float)\n",
    "\n",
    "# Drop Passengerid (axis=1 indicates we are removing a column rather than a row)\n",
    "# We drop passenger ID as it is not original data\n",
    "\n",
    "data.drop('PassengerId', inplace=True, axis=1)\n",
    "\n",
    "X = data.drop('Survived',axis=1) # X = all 'data' except the 'survived' column\n",
    "y = data['Survived'] # y = 'survived' column from 'data'\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training Dataset Samples: {len(X_train)}\")\n",
    "print(f\"Validation Dataset Samples: {len(X_validate)}\")\n",
    "print(f\"Testing Dataset Samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first set up a function to allow us to quickly pull back results for different machine learning models. This takes a model as the input and will output a series of metrics in a table to allow us to quickly compare and rank models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_train(name=\"XGBoost\",\n",
    "              X_train=X_train, X_validate=X_validate,\n",
    "              y_train=y_train, y_validate=y_validate,\n",
    "              model=XGBClassifier(random_state=42)\n",
    "              ):\n",
    "\n",
    "     model.fit(X_train, y_train)\n",
    "\n",
    "     y_pred_train = model.predict(X_train)\n",
    "     y_pred_val = model.predict(X_validate)\n",
    "\n",
    "     tn, fp, fn, tp = confusion_matrix(y_validate, y_pred_val, labels=[0, 1]).ravel()\n",
    "\n",
    "     return pd.DataFrame({\n",
    "            'Accuracy (training)': np.mean(y_pred_train == y_train),\n",
    "            'Accuracy (validation)': np.mean(y_pred_val == y_validate),\n",
    "            'Precision (validation)': precision_score(y_validate, y_pred_val, average='macro'),\n",
    "            'Recall (validation)': recall_score(y_validate, y_pred_val, average='macro'),\n",
    "            \"AUC\": roc_auc_score(y_validate, y_pred_val),\n",
    "            \"f1\": f1_score(y_validate, y_pred_val, average='macro'),\n",
    "            \"FP\": fp,\n",
    "            \"FN\": fn\n",
    "          }, index=[name]\n",
    ").round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first just train an XGBoost model to get an idea of the performance that can be achieved on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validation)</th>\n",
       "      <th>Precision (validation)</th>\n",
       "      <th>Recall (validation)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.787</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accuracy (training)  Accuracy (validation)  Precision (validation)  \\\n",
       "XGBoost                0.979                  0.797                   0.788   \n",
       "\n",
       "         Recall (validation)    AUC     f1  FP  FN  \n",
       "XGBoost                0.786  0.786  0.787  14  15  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = XGBClassifier(random_state=42)\n",
    "results_df = fit_train(model = clf1)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also train a decision tree for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = DecisionTreeClassifier(max_depth=6, random_state=42)\n",
    "results_df = pd.concat([results_df,fit_train(model=clf2, name=\"Decision Tree\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Ensemble: Using VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try creating an ensemble of these two models.\n",
    "\n",
    "We pass in a list containing a tuple per model; the tuple needs to have a name for the model, and the model object itself.\n",
    "\n",
    "Here, we've chosen 'hard' voting, which means it just looks at the prediction from each model and uses the majority vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier_1 = VotingClassifier(\n",
    "    estimators=[('dt', clf1), ('xGB', clf2)],\n",
    "    voting='hard')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then just use our fit_train function on this, appending the results to the end of our existing results_df.\n",
    "\n",
    "The output of `VotingClassifier` is a model object - just as if we'd created a `RandomForestClassifier()` or `XGBClassifier()`. This means we can use all of the normal features like `.fit()` and `.predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validation)</th>\n",
       "      <th>Precision (validation)</th>\n",
       "      <th>Recall (validation)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.787</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.805</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGB: hard</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.817</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy (training)  Accuracy (validation)  \\\n",
       "XGBoost                      0.979                  0.797   \n",
       "Decision Tree                0.886                  0.818   \n",
       "DT, XGB: hard                0.898                  0.832   \n",
       "\n",
       "               Precision (validation)  Recall (validation)    AUC     f1  FP  \\\n",
       "XGBoost                         0.788                0.786  0.786  0.787  14   \n",
       "Decision Tree                   0.814                0.800  0.800  0.805  10   \n",
       "DT, XGB: hard                   0.836                0.808  0.808  0.817   7   \n",
       "\n",
       "               FN  \n",
       "XGBoost        15  \n",
       "Decision Tree  16  \n",
       "DT, XGB: hard  17  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.concat(\n",
    "    [results_df,\n",
    "     fit_train(model=voting_classifier_1, name=\"DT, XGB: hard\")]\n",
    "     )\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with more classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try this with some additional models.\n",
    "\n",
    "We're going to use some additional models that require the data to be *standardised*, so let's do that first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Apply the scaler to the training and test sets\n",
    "X_train_standardised = sc.fit_transform(X_train)\n",
    "X_validate_standardised = sc.fit_transform(X_validate)\n",
    "X_test_standardised = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Additional Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "clf4 = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "clf5 = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more complex voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier_2 = VotingClassifier(estimators=[\n",
    "    ('XGBoost', clf1),\n",
    "    ('Decision Tree', clf2),\n",
    "    ('K-Nearest Neighbours', clf3),\n",
    "    ('SVC', clf4),\n",
    "    ('Logistic Regression', clf5)\n",
    "    ],\n",
    "    voting='hard')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now just append our results and view our updated table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validation)</th>\n",
       "      <th>Precision (validation)</th>\n",
       "      <th>Recall (validation)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.787</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.805</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGB: hard</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.817</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGBoost, KNN, LogReg + SVC: hard</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.785</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Accuracy (training)  \\\n",
       "XGBoost                                             0.979   \n",
       "Decision Tree                                       0.886   \n",
       "DT, XGB: hard                                       0.898   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                0.880   \n",
       "\n",
       "                                      Accuracy (validation)  \\\n",
       "XGBoost                                               0.797   \n",
       "Decision Tree                                         0.818   \n",
       "DT, XGB: hard                                         0.832   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                  0.797   \n",
       "\n",
       "                                      Precision (validation)  \\\n",
       "XGBoost                                                0.788   \n",
       "Decision Tree                                          0.814   \n",
       "DT, XGB: hard                                          0.836   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                   0.788   \n",
       "\n",
       "                                      Recall (validation)    AUC     f1  FP  \\\n",
       "XGBoost                                             0.786  0.786  0.787  14   \n",
       "Decision Tree                                       0.800  0.800  0.805  10   \n",
       "DT, XGB: hard                                       0.808  0.808  0.817   7   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                0.782  0.782  0.785  13   \n",
       "\n",
       "                                      FN  \n",
       "XGBoost                               15  \n",
       "Decision Tree                         16  \n",
       "DT, XGB: hard                         17  \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard  16  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results_df = pd.concat([\n",
    "    results_df,\n",
    "    fit_train(\n",
    "        X_train=X_train_standardised,\n",
    "        X_validate=X_validate_standardised,\n",
    "        model=voting_classifier_2,\n",
    "        name=\"DT, XGBoost, KNN, LogReg + SVC: hard\")\n",
    "        ])\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard and Soft Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We previously used the 'hard' voting parameter, which looks at the predicted class from each classifier and takes the majority vote.\n",
    "\n",
    "Instead, the 'soft' classifier looks at the predicted probabilities from each classifier and averages them. \n",
    "\n",
    "This does mean that each model that is passed in must have a `.predict_proba()` method - most do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validation)</th>\n",
       "      <th>Precision (validation)</th>\n",
       "      <th>Recall (validation)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.787</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.805</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGB: hard</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.817</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGBoost, KNN, LogReg + SVC: hard</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.785</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGB: soft</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Accuracy (training)  \\\n",
       "XGBoost                                             0.979   \n",
       "Decision Tree                                       0.886   \n",
       "DT, XGB: hard                                       0.898   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                0.880   \n",
       "DT, XGB: soft                                       0.951   \n",
       "\n",
       "                                      Accuracy (validation)  \\\n",
       "XGBoost                                               0.797   \n",
       "Decision Tree                                         0.818   \n",
       "DT, XGB: hard                                         0.832   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                  0.797   \n",
       "DT, XGB: soft                                         0.804   \n",
       "\n",
       "                                      Precision (validation)  \\\n",
       "XGBoost                                                0.788   \n",
       "Decision Tree                                          0.814   \n",
       "DT, XGB: hard                                          0.836   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                   0.788   \n",
       "DT, XGB: soft                                          0.795   \n",
       "\n",
       "                                      Recall (validation)    AUC     f1  FP  \\\n",
       "XGBoost                                             0.786  0.786  0.787  14   \n",
       "Decision Tree                                       0.800  0.800  0.805  10   \n",
       "DT, XGB: hard                                       0.808  0.808  0.817   7   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                0.782  0.782  0.785  13   \n",
       "DT, XGB: soft                                       0.795  0.795  0.795  14   \n",
       "\n",
       "                                      FN  \n",
       "XGBoost                               15  \n",
       "Decision Tree                         16  \n",
       "DT, XGB: hard                         17  \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard  16  \n",
       "DT, XGB: soft                         14  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier_1 = VotingClassifier(\n",
    "    estimators=[('dt', clf1), ('xGB', clf2)],\n",
    "    voting='soft')\n",
    "\n",
    "results_df = pd.concat(\n",
    "    [results_df,\n",
    "     fit_train(model=voting_classifier_1, name=\"DT, XGB: soft\")]\n",
    "     )\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting classifiers\n",
    "\n",
    "Whether working with hard or soft voting, we can also weight the predictions of different models.\n",
    "\n",
    "Here, we give the prediction of the decision tree twice the weight of the XGBoost Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validation)</th>\n",
       "      <th>Precision (validation)</th>\n",
       "      <th>Recall (validation)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.787</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.805</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGB: hard</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.817</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGBoost, KNN, LogReg + SVC: hard</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.785</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGB: soft</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGB: soft, 2:1</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.808</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Accuracy (training)  \\\n",
       "XGBoost                                             0.979   \n",
       "Decision Tree                                       0.886   \n",
       "DT, XGB: hard                                       0.898   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                0.880   \n",
       "DT, XGB: soft                                       0.951   \n",
       "DT, XGB: soft, 2:1                                  0.924   \n",
       "\n",
       "                                      Accuracy (validation)  \\\n",
       "XGBoost                                               0.797   \n",
       "Decision Tree                                         0.818   \n",
       "DT, XGB: hard                                         0.832   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                  0.797   \n",
       "DT, XGB: soft                                         0.804   \n",
       "DT, XGB: soft, 2:1                                    0.818   \n",
       "\n",
       "                                      Precision (validation)  \\\n",
       "XGBoost                                                0.788   \n",
       "Decision Tree                                          0.814   \n",
       "DT, XGB: hard                                          0.836   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                   0.788   \n",
       "DT, XGB: soft                                          0.795   \n",
       "DT, XGB: soft, 2:1                                     0.810   \n",
       "\n",
       "                                      Recall (validation)    AUC     f1  FP  \\\n",
       "XGBoost                                             0.786  0.786  0.787  14   \n",
       "Decision Tree                                       0.800  0.800  0.805  10   \n",
       "DT, XGB: hard                                       0.808  0.808  0.817   7   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                0.782  0.782  0.785  13   \n",
       "DT, XGB: soft                                       0.795  0.795  0.795  14   \n",
       "DT, XGB: soft, 2:1                                  0.806  0.806  0.808  12   \n",
       "\n",
       "                                      FN  \n",
       "XGBoost                               15  \n",
       "Decision Tree                         16  \n",
       "DT, XGB: hard                         17  \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard  16  \n",
       "DT, XGB: soft                         14  \n",
       "DT, XGB: soft, 2:1                    14  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier_1 = VotingClassifier(\n",
    "    estimators=[('dt', clf1), ('xGB', clf2)],\n",
    "    voting='soft',\n",
    "    weights=[1, 2])\n",
    "\n",
    "results_df = pd.concat(\n",
    "    [results_df,\n",
    "     fit_train(model=voting_classifier_1, name=\"DT, XGB: soft, 2:1\")]\n",
    "     )\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply each of these to more complex ensembles. Here, let's try soft voting with our 5-model ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validation)</th>\n",
       "      <th>Precision (validation)</th>\n",
       "      <th>Recall (validation)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.787</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.805</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGB: hard</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.817</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGBoost, KNN, LogReg + SVC: hard</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.785</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGB: soft</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGB: soft, 2:1</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.808</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGBoost, KNN + SVC: soft</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.800</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Accuracy (training)  \\\n",
       "XGBoost                                             0.979   \n",
       "Decision Tree                                       0.886   \n",
       "DT, XGB: hard                                       0.898   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                0.880   \n",
       "DT, XGB: soft                                       0.951   \n",
       "DT, XGB: soft, 2:1                                  0.924   \n",
       "DT, XGBoost, KNN + SVC: soft                        0.916   \n",
       "\n",
       "                                      Accuracy (validation)  \\\n",
       "XGBoost                                               0.797   \n",
       "Decision Tree                                         0.818   \n",
       "DT, XGB: hard                                         0.832   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                  0.797   \n",
       "DT, XGB: soft                                         0.804   \n",
       "DT, XGB: soft, 2:1                                    0.818   \n",
       "DT, XGBoost, KNN + SVC: soft                          0.811   \n",
       "\n",
       "                                      Precision (validation)  \\\n",
       "XGBoost                                                0.788   \n",
       "Decision Tree                                          0.814   \n",
       "DT, XGB: hard                                          0.836   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                   0.788   \n",
       "DT, XGB: soft                                          0.795   \n",
       "DT, XGB: soft, 2:1                                     0.810   \n",
       "DT, XGBoost, KNN + SVC: soft                           0.803   \n",
       "\n",
       "                                      Recall (validation)    AUC     f1  FP  \\\n",
       "XGBoost                                             0.786  0.786  0.787  14   \n",
       "Decision Tree                                       0.800  0.800  0.805  10   \n",
       "DT, XGB: hard                                       0.808  0.808  0.817   7   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                0.782  0.782  0.785  13   \n",
       "DT, XGB: soft                                       0.795  0.795  0.795  14   \n",
       "DT, XGB: soft, 2:1                                  0.806  0.806  0.808  12   \n",
       "DT, XGBoost, KNN + SVC: soft                        0.797  0.797  0.800  12   \n",
       "\n",
       "                                      FN  \n",
       "XGBoost                               15  \n",
       "Decision Tree                         16  \n",
       "DT, XGB: hard                         17  \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard  16  \n",
       "DT, XGB: soft                         14  \n",
       "DT, XGB: soft, 2:1                    14  \n",
       "DT, XGBoost, KNN + SVC: soft          15  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier_2 = VotingClassifier(estimators=[\n",
    "    ('XGBoost', clf1),\n",
    "    ('Decision Tree', clf2),\n",
    "    ('K-Nearest Neighbours', clf3),\n",
    "    ('SVC', clf4),\n",
    "    ('Logistic Regression', clf5)\n",
    "    ],\n",
    "    voting='soft')\n",
    "\n",
    "results_df = pd.concat([\n",
    "    results_df,\n",
    "    fit_train(\n",
    "        X_train=X_train_standardised,\n",
    "        X_validate=X_validate_standardised,\n",
    "        model=voting_classifier_2,\n",
    "        name=\"DT, XGBoost, KNN + SVC: soft\")])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try weighting this and see the impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validation)</th>\n",
       "      <th>Precision (validation)</th>\n",
       "      <th>Recall (validation)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.787</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.805</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGB: hard</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.817</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGBoost, KNN, LogReg + SVC: hard</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.785</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGB: soft</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGB: soft, 2:1</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.808</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGBoost, KNN + SVC: soft</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.800</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT, XGBoost, KNN + SVC: soft, 2:2:1:1:2</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.807</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Accuracy (training)  \\\n",
       "XGBoost                                                0.979   \n",
       "Decision Tree                                          0.886   \n",
       "DT, XGB: hard                                          0.898   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                   0.880   \n",
       "DT, XGB: soft                                          0.951   \n",
       "DT, XGB: soft, 2:1                                     0.924   \n",
       "DT, XGBoost, KNN + SVC: soft                           0.916   \n",
       "DT, XGBoost, KNN + SVC: soft, 2:2:1:1:2                0.923   \n",
       "\n",
       "                                         Accuracy (validation)  \\\n",
       "XGBoost                                                  0.797   \n",
       "Decision Tree                                            0.818   \n",
       "DT, XGB: hard                                            0.832   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                     0.797   \n",
       "DT, XGB: soft                                            0.804   \n",
       "DT, XGB: soft, 2:1                                       0.818   \n",
       "DT, XGBoost, KNN + SVC: soft                             0.811   \n",
       "DT, XGBoost, KNN + SVC: soft, 2:2:1:1:2                  0.818   \n",
       "\n",
       "                                         Precision (validation)  \\\n",
       "XGBoost                                                   0.788   \n",
       "Decision Tree                                             0.814   \n",
       "DT, XGB: hard                                             0.836   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                      0.788   \n",
       "DT, XGB: soft                                             0.795   \n",
       "DT, XGB: soft, 2:1                                        0.810   \n",
       "DT, XGBoost, KNN + SVC: soft                              0.803   \n",
       "DT, XGBoost, KNN + SVC: soft, 2:2:1:1:2                   0.812   \n",
       "\n",
       "                                         Recall (validation)    AUC     f1  \\\n",
       "XGBoost                                                0.786  0.786  0.787   \n",
       "Decision Tree                                          0.800  0.800  0.805   \n",
       "DT, XGB: hard                                          0.808  0.808  0.817   \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard                   0.782  0.782  0.785   \n",
       "DT, XGB: soft                                          0.795  0.795  0.795   \n",
       "DT, XGB: soft, 2:1                                     0.806  0.806  0.808   \n",
       "DT, XGBoost, KNN + SVC: soft                           0.797  0.797  0.800   \n",
       "DT, XGBoost, KNN + SVC: soft, 2:2:1:1:2                0.803  0.803  0.807   \n",
       "\n",
       "                                         FP  FN  \n",
       "XGBoost                                  14  15  \n",
       "Decision Tree                            10  16  \n",
       "DT, XGB: hard                             7  17  \n",
       "DT, XGBoost, KNN, LogReg + SVC: hard     13  16  \n",
       "DT, XGB: soft                            14  14  \n",
       "DT, XGB: soft, 2:1                       12  14  \n",
       "DT, XGBoost, KNN + SVC: soft             12  15  \n",
       "DT, XGBoost, KNN + SVC: soft, 2:2:1:1:2  11  15  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier_2 = VotingClassifier(estimators=[\n",
    "    ('XGBoost', clf1),\n",
    "    ('Decision Tree', clf2),\n",
    "    ('K-Nearest Neighbours', clf3),\n",
    "    ('SVC', clf4),\n",
    "    ('Logistic Regression', clf5)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[2,2,1,1,2])\n",
    "\n",
    "results_df = pd.concat([\n",
    "    results_df,\n",
    "    fit_train(\n",
    "        X_train=X_train_standardised,\n",
    "        X_validate=X_validate_standardised,\n",
    "        model=voting_classifier_2,\n",
    "        name=\"DT, XGBoost, KNN + SVC: soft, 2:2:1:1:2\")])\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
