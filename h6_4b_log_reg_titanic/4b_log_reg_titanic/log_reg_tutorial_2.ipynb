{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic survival - logistic regression model\n",
    "\n",
    "Can we predict which passengers would survive the sinking of the Titanic?\n",
    "\n",
    "See:\n",
    "\n",
    "https://www.kaggle.com/c/titanic/overview/evaluation\n",
    "\n",
    "https://michaelallen1966.github.io/titanic/front_page.html\n",
    "\n",
    "The original data comes from:\n",
    "\n",
    "https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "Though we will download and use a data set that has been pre-processed ready for machine learning.  IMPORTANT - real data that you will work with will need preprocessing first.  There's a handy guide to preprocessing data here (based on the Titanic data we're using) : https://michaelallen1966.github.io/titanic/01_preprocessing.html\n",
    "\n",
    "The data includes:\n",
    "\n",
    "Variable  | Definition\n",
    "----------|-----------\n",
    "survival  | Survival (0 = No, 1 = Yes)\n",
    "pclass    | Ticket class\n",
    "sex       | Sex\n",
    "Age       | Age in years\n",
    "sibsp     | # of siblings / spouses aboard the Titanic\n",
    "parch     | # of parents / children aboard the Titanic\n",
    "ticket    | Ticket number\n",
    "fare      | Passenger fare\n",
    "cabin     | Cabin number\n",
    "embarked  | Port of Embarkation(C=Cherbourg, Q=Queenstown, S=Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "In this example we will use logistic regression (see https://en.wikipedia.org/wiki/Logistic_regression).\n",
    "\n",
    "For an introductory video on logistic regression see: https://www.youtube.com/watch?v=yIYKR4sgzI8\n",
    "\n",
    "Logistic regression takes a range of features (which we will normalise/standardise to put on the same scale) and returns a probability that a certain classification (survival in this case) is true.\n",
    "\n",
    "We will go through the following steps:\n",
    "\n",
    "* Download and save pre-processed data\n",
    "* Split data into features (X) and label (y)\n",
    "* Split data into training and test sets (we will test on data that has not been used to fit the model)\n",
    "* Standardise data\n",
    "* Fit a logistic regression model (from sklearn)\n",
    "* Predict survival of the test set, and assess accuracy\n",
    "* Review model coefficients (weights) to see importance of features\n",
    "* Show probability of survival for passengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules\n",
    "\n",
    "A standard Anaconda install of Python (https://www.anaconda.com/distribution/) contains all the necessary modules.  Use your base environment if in doubt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import machine learning methods\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "The section below downloads pre-processed data, and saves it to a subfolder (from where this code is run).\n",
    "If data has already been downloaded that cell may be skipped.\n",
    "\n",
    "Code that was used to pre-process the data ready for machine learning may be found at:\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/01_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_required = True\n",
    "\n",
    "if download_required:\n",
    "    \n",
    "    # Download processed data:\n",
    "    address = 'https://raw.githubusercontent.com/MichaelAllen1966/' + \\\n",
    "                '1804_python_healthcare/master/titanic/data/processed_data.csv'\n",
    "    \n",
    "    data = pd.read_csv(address)\n",
    "\n",
    "    # Create a data subfolder if one does not already exist\n",
    "    import os\n",
    "    data_directory ='./data/'\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    # Save data\n",
    "    data.to_csv(data_directory + 'processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_data.csv')\n",
    "# Make all data 'float' type\n",
    "data = data.astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine loaded data\n",
    "\n",
    "The data is in the form of a Pandas DataFrame, so we have column headers providing information of what is contained in each column.\n",
    "\n",
    "We will use the DataFrame `.head()` method to show the first few rows of the imported DataFrame. By default this shows the first 5 rows. Here we will look at the first 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>AgeImputed</th>\n",
       "      <th>EmbarkedImputed</th>\n",
       "      <th>CabinLetterImputed</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked_missing</th>\n",
       "      <th>CabinLetter_A</th>\n",
       "      <th>CabinLetter_B</th>\n",
       "      <th>CabinLetter_C</th>\n",
       "      <th>CabinLetter_D</th>\n",
       "      <th>CabinLetter_E</th>\n",
       "      <th>CabinLetter_F</th>\n",
       "      <th>CabinLetter_G</th>\n",
       "      <th>CabinLetter_T</th>\n",
       "      <th>CabinLetter_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  AgeImputed  \\\n",
       "0          1.0       0.0     3.0  22.0    1.0    0.0   7.2500         0.0   \n",
       "1          2.0       1.0     1.0  38.0    1.0    0.0  71.2833         0.0   \n",
       "2          3.0       1.0     3.0  26.0    0.0    0.0   7.9250         0.0   \n",
       "3          4.0       1.0     1.0  35.0    1.0    0.0  53.1000         0.0   \n",
       "4          5.0       0.0     3.0  35.0    0.0    0.0   8.0500         0.0   \n",
       "5          6.0       0.0     3.0  28.0    0.0    0.0   8.4583         1.0   \n",
       "6          7.0       0.0     1.0  54.0    0.0    0.0  51.8625         0.0   \n",
       "7          8.0       0.0     3.0   2.0    3.0    1.0  21.0750         0.0   \n",
       "8          9.0       1.0     3.0  27.0    0.0    2.0  11.1333         0.0   \n",
       "9         10.0       1.0     2.0  14.0    1.0    0.0  30.0708         0.0   \n",
       "\n",
       "   EmbarkedImputed  CabinLetterImputed  ...  Embarked_missing  CabinLetter_A  \\\n",
       "0              0.0                 1.0  ...               0.0            0.0   \n",
       "1              0.0                 0.0  ...               0.0            0.0   \n",
       "2              0.0                 1.0  ...               0.0            0.0   \n",
       "3              0.0                 0.0  ...               0.0            0.0   \n",
       "4              0.0                 1.0  ...               0.0            0.0   \n",
       "5              0.0                 1.0  ...               0.0            0.0   \n",
       "6              0.0                 0.0  ...               0.0            0.0   \n",
       "7              0.0                 1.0  ...               0.0            0.0   \n",
       "8              0.0                 1.0  ...               0.0            0.0   \n",
       "9              0.0                 1.0  ...               0.0            0.0   \n",
       "\n",
       "   CabinLetter_B  CabinLetter_C  CabinLetter_D  CabinLetter_E  CabinLetter_F  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            1.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "3            0.0            1.0            0.0            0.0            0.0   \n",
       "4            0.0            0.0            0.0            0.0            0.0   \n",
       "5            0.0            0.0            0.0            0.0            0.0   \n",
       "6            0.0            0.0            0.0            1.0            0.0   \n",
       "7            0.0            0.0            0.0            0.0            0.0   \n",
       "8            0.0            0.0            0.0            0.0            0.0   \n",
       "9            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   CabinLetter_G  CabinLetter_T  CabinLetter_missing  \n",
       "0            0.0            0.0                  1.0  \n",
       "1            0.0            0.0                  0.0  \n",
       "2            0.0            0.0                  1.0  \n",
       "3            0.0            0.0                  0.0  \n",
       "4            0.0            0.0                  1.0  \n",
       "5            0.0            0.0                  1.0  \n",
       "6            0.0            0.0                  0.0  \n",
       "7            0.0            0.0                  1.0  \n",
       "8            0.0            0.0                  1.0  \n",
       "9            0.0            0.0                  1.0  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above, \"Imputed\" column names indicate whether that feature was blank in the original data and was filled in (\"imputed\") in the preprocessing (so \"AgeImputed\" value of 1.0 means the age was missing, 0.0 means it wasn't).  You can't have missing cells in Machine Learning, so you have to decide what to do when you have missing data.  This is part of the pre-processing step you'll need to do with real data, and there's more information about this in the pre-processing notebook here : https://michaelallen1966.github.io/titanic/01_preprocessing.html\n",
    "\n",
    "We can also show a summary of the data with the `.describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>AgeImputed</th>\n",
       "      <th>EmbarkedImputed</th>\n",
       "      <th>CabinLetterImputed</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked_missing</th>\n",
       "      <th>CabinLetter_A</th>\n",
       "      <th>CabinLetter_B</th>\n",
       "      <th>CabinLetter_C</th>\n",
       "      <th>CabinLetter_D</th>\n",
       "      <th>CabinLetter_E</th>\n",
       "      <th>CabinLetter_F</th>\n",
       "      <th>CabinLetter_G</th>\n",
       "      <th>CabinLetter_T</th>\n",
       "      <th>CabinLetter_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.361582</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.198653</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.771044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.016835</td>\n",
       "      <td>0.052750</td>\n",
       "      <td>0.066218</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.035915</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.771044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.019697</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.399210</td>\n",
       "      <td>0.047351</td>\n",
       "      <td>0.420397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047351</td>\n",
       "      <td>0.128725</td>\n",
       "      <td>0.223659</td>\n",
       "      <td>0.248802</td>\n",
       "      <td>0.188959</td>\n",
       "      <td>0.186182</td>\n",
       "      <td>0.119973</td>\n",
       "      <td>0.066890</td>\n",
       "      <td>0.033501</td>\n",
       "      <td>0.420397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.361582    0.523008   \n",
       "std     257.353842    0.486592    0.836071   13.019697    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  AgeImputed  EmbarkedImputed  \\\n",
       "count  891.000000  891.000000  891.000000       891.000000   \n",
       "mean     0.381594   32.204208    0.198653         0.002245   \n",
       "std      0.806057   49.693429    0.399210         0.047351   \n",
       "min      0.000000    0.000000    0.000000         0.000000   \n",
       "25%      0.000000    7.910400    0.000000         0.000000   \n",
       "50%      0.000000   14.454200    0.000000         0.000000   \n",
       "75%      0.000000   31.000000    0.000000         0.000000   \n",
       "max      6.000000  512.329200    1.000000         1.000000   \n",
       "\n",
       "       CabinLetterImputed  ...  Embarked_missing  CabinLetter_A  \\\n",
       "count          891.000000  ...        891.000000     891.000000   \n",
       "mean             0.771044  ...          0.002245       0.016835   \n",
       "std              0.420397  ...          0.047351       0.128725   \n",
       "min              0.000000  ...          0.000000       0.000000   \n",
       "25%              1.000000  ...          0.000000       0.000000   \n",
       "50%              1.000000  ...          0.000000       0.000000   \n",
       "75%              1.000000  ...          0.000000       0.000000   \n",
       "max              1.000000  ...          1.000000       1.000000   \n",
       "\n",
       "       CabinLetter_B  CabinLetter_C  CabinLetter_D  CabinLetter_E  \\\n",
       "count     891.000000     891.000000     891.000000     891.000000   \n",
       "mean        0.052750       0.066218       0.037037       0.035915   \n",
       "std         0.223659       0.248802       0.188959       0.186182   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       CabinLetter_F  CabinLetter_G  CabinLetter_T  CabinLetter_missing  \n",
       "count     891.000000     891.000000     891.000000           891.000000  \n",
       "mean        0.014590       0.004489       0.001122             0.771044  \n",
       "std         0.119973       0.066890       0.033501             0.420397  \n",
       "min         0.000000       0.000000       0.000000             0.000000  \n",
       "25%         0.000000       0.000000       0.000000             1.000000  \n",
       "50%         0.000000       0.000000       0.000000             1.000000  \n",
       "75%         0.000000       0.000000       0.000000             1.000000  \n",
       "max         1.000000       1.000000       1.000000             1.000000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is a passenger index number. We will remove this, as this is not part of the original Titanic passenger data, and will not help us train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Passengerid (axis=1 indicates we are removing a column rather than a row)\n",
    "# We drop passenger ID as it is not original data\n",
    "# inplace=True means change the dataframe itself - don't create a copy with this column dropped\n",
    "\n",
    "data.drop('PassengerId', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at a summary of passengers who survived or did not survive\n",
    "\n",
    "Before running machine learning models, it is always good to have a look at your data. Here we will separate passengers who survived from those who died, and we will have a look at differences in features.\n",
    "\n",
    "We will use a *mask* to select and filter passengers.  The mask applies Boolean values (True and False) to entries depending on a given condition.  Below, we use this to create a mask that has True values for any rows where the Survived value is 1.0 (ie where the patient survived), and then store only those rows in a separate dataframe called \"survived\".  Then we do the same thing but for those who died."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['Survived'] == 1 # Mask for passengers who survive\n",
    "survived = data[mask] # filter using mask\n",
    "\n",
    "mask = data['Survived'] == 0 # Mask for passengers who died\n",
    "died = data[mask] # filter using mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at average (mean) values for each feature for those who `survived` and those who `died`.  We can make comparing them easier by putting these values in a new DataFrame so we can look at them side by side.  What do you notice?  What features do you think might have influenced survival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame() # New empty DataFrame\n",
    "summary['survived'] = survived.mean()\n",
    "summary['died'] = died.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>died</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>1.950292</td>\n",
       "      <td>2.531876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>28.291433</td>\n",
       "      <td>30.028233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.553734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.464912</td>\n",
       "      <td>0.329690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>48.395408</td>\n",
       "      <td>22.117887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeImputed</th>\n",
       "      <td>0.152047</td>\n",
       "      <td>0.227687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EmbarkedImputed</th>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CabinLetterImputed</th>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.876138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CabinNumber</th>\n",
       "      <td>18.961988</td>\n",
       "      <td>6.074681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CabinNumberImputed</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.885246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.318713</td>\n",
       "      <td>0.852459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>0.271930</td>\n",
       "      <td>0.136612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.085610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>0.634503</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_missing</th>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CabinLetter_A</th>\n",
       "      <td>0.020468</td>\n",
       "      <td>0.014572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CabinLetter_B</th>\n",
       "      <td>0.102339</td>\n",
       "      <td>0.021858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CabinLetter_C</th>\n",
       "      <td>0.102339</td>\n",
       "      <td>0.043716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CabinLetter_D</th>\n",
       "      <td>0.073099</td>\n",
       "      <td>0.014572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CabinLetter_E</th>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.014572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CabinLetter_F</th>\n",
       "      <td>0.023392</td>\n",
       "      <td>0.009107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CabinLetter_G</th>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CabinLetter_T</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CabinLetter_missing</th>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.876138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      survived       died\n",
       "Survived              1.000000   0.000000\n",
       "Pclass                1.950292   2.531876\n",
       "Age                  28.291433  30.028233\n",
       "SibSp                 0.473684   0.553734\n",
       "Parch                 0.464912   0.329690\n",
       "Fare                 48.395408  22.117887\n",
       "AgeImputed            0.152047   0.227687\n",
       "EmbarkedImputed       0.005848   0.000000\n",
       "CabinLetterImputed    0.602339   0.876138\n",
       "CabinNumber          18.961988   6.074681\n",
       "CabinNumberImputed    0.611111   0.885246\n",
       "male                  0.318713   0.852459\n",
       "Embarked_C            0.271930   0.136612\n",
       "Embarked_Q            0.087719   0.085610\n",
       "Embarked_S            0.634503   0.777778\n",
       "Embarked_missing      0.005848   0.000000\n",
       "CabinLetter_A         0.020468   0.014572\n",
       "CabinLetter_B         0.102339   0.021858\n",
       "CabinLetter_C         0.102339   0.043716\n",
       "CabinLetter_D         0.073099   0.014572\n",
       "CabinLetter_E         0.070175   0.014572\n",
       "CabinLetter_F         0.023392   0.009107\n",
       "CabinLetter_G         0.005848   0.003643\n",
       "CabinLetter_T         0.000000   0.001821\n",
       "CabinLetter_missing   0.602339   0.876138"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into X (features) and y (labels)\n",
    "\n",
    "We will separate out our features (the data we use to make a prediction) from our label (what we are trying to predict - survival here).\n",
    "By convention our features are called `X` (usually upper case to denote multiple features), and the label (survived or not) `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Survived',axis=1) # X = all 'data' except the 'survived' column\n",
    "y = data['Survived'] # y = 'survived' column from 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into training and tets sets\n",
    "\n",
    "When we test a machine learning model we should always test it on data that has not been used to train the model.\n",
    "We will use sklearn's `train_test_split` method to randomly split the data: 75% for training, and 25% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25) # 75% training data, 25% test data; this function returns 4 datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the standard deviation and the mean of the feature values in the training data (Standard Deviation for each feature shown first, then mean for each feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pclass                  0.843576\n",
       " Age                    12.673098\n",
       " SibSp                   1.072346\n",
       " Parch                   0.797229\n",
       " Fare                   49.760045\n",
       " AgeImputed              0.404070\n",
       " EmbarkedImputed         0.038691\n",
       " CabinLetterImputed      0.421493\n",
       " CabinNumber            27.416623\n",
       " CabinNumberImputed      0.415606\n",
       " male                    0.478808\n",
       " Embarked_C              0.396197\n",
       " Embarked_Q              0.270473\n",
       " Embarked_S              0.447075\n",
       " Embarked_missing        0.038691\n",
       " CabinLetter_A           0.121524\n",
       " CabinLetter_B           0.225974\n",
       " CabinLetter_C           0.260911\n",
       " CabinLetter_D           0.207262\n",
       " CabinLetter_E           0.157603\n",
       " CabinLetter_F           0.115375\n",
       " CabinLetter_G           0.054677\n",
       " CabinLetter_T           0.038691\n",
       " CabinLetter_missing     0.421493\n",
       " dtype: float64,\n",
       " Pclass                  2.279940\n",
       " Age                    29.448982\n",
       " SibSp                   0.500000\n",
       " Parch                   0.371257\n",
       " Fare                   32.723084\n",
       " AgeImputed              0.205090\n",
       " EmbarkedImputed         0.001497\n",
       " CabinLetterImputed      0.769461\n",
       " CabinNumber            11.479042\n",
       " CabinNumberImputed      0.778443\n",
       " male                    0.645210\n",
       " Embarked_C              0.194611\n",
       " Embarked_Q              0.079341\n",
       " Embarked_S              0.724551\n",
       " Embarked_missing        0.001497\n",
       " CabinLetter_A           0.014970\n",
       " CabinLetter_B           0.053892\n",
       " CabinLetter_C           0.073353\n",
       " CabinLetter_D           0.044910\n",
       " CabinLetter_E           0.025449\n",
       " CabinLetter_F           0.013473\n",
       " CabinLetter_G           0.002994\n",
       " CabinLetter_T           0.001497\n",
       " CabinLetter_missing     0.769461\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.std(), X_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardise data\n",
    "\n",
    "We can see above that there are quite different scales across different features in this data.  For example, passenger class is on a very different scale numerically than the fare paid.\n",
    "\n",
    "We want all of our features to be on roughly the same scale. This generally leads to a better model, and also allows us to more easily compare the importance of different features.\n",
    "\n",
    "We will use standardisation to scale our feature values, where we use the mean and standard deviation of the training set of data to normalise the data. We subtract the mean of the training set values, and divide by the standard deviation of the training data. Note that the mean and standard deviation of the training data are used to standardise the test set data as well.\n",
    "\n",
    "Here we will use sklearn's `StandardScaler method`. This method also copes with problems we might otherwise have (such as if one feature has zero standard deviation in the training set).  We write a little function so whenever we need to standardise some data, we can just call this function, pass in the training and test feature (X) data, and it'll return the same data but standardised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_data(X_train, X_test):\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc = StandardScaler() \n",
    "\n",
    "    # Apply the scaler to the training and test sets\n",
    "    train_std=sc.fit_transform(X_train)\n",
    "    test_std=sc.fit_transform(X_test)\n",
    "    \n",
    "    return train_std, test_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call this function and use it to standardise our training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std, X_test_std = standardise_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit logistic regression model\n",
    "\n",
    "Now we will fit a logistic regression model, using sklearn's `LogisticRegression` method. Our machine learning model fitting (training) is only two lines of code!\n",
    "By using the name `model` for our logistic regression model we will make our model more interchangeable later on if we wanted to try a different kind of model, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_std,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict values\n",
    "\n",
    "Now we can use the trained model to predict survival. We will test the accuracy of both the training and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict training and test set labels\n",
    "y_pred_train = model.predict(X_train_std)\n",
    "y_pred_test = model.predict(X_test_std)\n",
    "\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracy\n",
    "\n",
    "In this example we will measure accuracy simply as the proportion of passengers where we make the correct prediction. In later examples we will look at other measures of accuracy which explore false positives and false negatives in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of predicting training data = 0.8158682634730539\n",
      "Accuracy of predicting test data = 0.8071748878923767\n"
     ]
    }
   ],
   "source": [
    "# The shorthand below says to check each predicted y value against the actual\n",
    "# y value in the training data.  This gives a list of True and False values\n",
    "# for each prediction, where True indicates the predicted value matches the\n",
    "# actual value.  Then we take the mean of these Boolean values, which gives\n",
    "# us a proportion (where if all values were True, the proportion would be 1.0)\n",
    "# If you want to see why that works, just uncomment the following line of code\n",
    "# to see what y_pred_train == y_train is doing.\n",
    "# print (y_pred_train == y_train)\n",
    "accuracy_train = np.mean(y_pred_train == y_train)\n",
    "accuracy_test = np.mean(y_pred_test == y_test)\n",
    "\n",
    "print (f'Accuracy of predicting training data = {accuracy_train}')\n",
    "print (f'Accuracy of predicting test data = {accuracy_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad - about 80% accuracy. You will probably see that accuracy of predicting the training set is usually higher than the test set. Because we are only testing one random sample, you may occasionally see otherwise. In later examples we will look at the best way to repeat multiple tests, and look at what to do if the accuracy of the training set is significantly higher than the test set (a problem called 'overfitting')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the model coefficients (weights)\n",
    "\n",
    "Not all features are equally important. And some may be of little or no use at all, unnecessarily increasing the complexity of the model. In later examples we will look at selecting features which add value to the model (or removing features that don’t).\n",
    "\n",
    "Here we will look at the importance of features – how they affect our estimation of survival. These are known as the model *coefficients* (if you come from a traditional statistics background), or model *weights* (if you come from a machine learning background). \n",
    "\n",
    "Because we have standardised our input data the magnitude of the weights may be compared as an indicator of their influence in the model. Weights with higher negative numbers mean that that feature correlates with reduced chance of survival. Weights with higher positive numbers mean that that feature correlates with increased chance of survival. Those weights with values closer to zero (either positive or negative) have less influence in the model.\n",
    "\n",
    "We access the model weights my examining the model `coef_` attribute. The model may predict more than one outcome label, in which case we have weights for each label. Because we are predicting a single label here (survive or not), the weights are found in the first element (`[0]`) of the `coef_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.73381594, -0.60661187, -0.46209945, -0.03989834,  0.01322658,\n",
       "       -0.21036039,  0.07407032,  0.08101972, -0.20637484, -0.73348479,\n",
       "       -1.32721002,  0.07134322,  0.13877394, -0.15359055,  0.07407032,\n",
       "       -0.09519898, -0.04608342, -0.07319769,  0.01816173,  0.06896468,\n",
       "        0.02347437, -0.09324047, -0.13729623,  0.08101972])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_eff = model.coef_[0]\n",
    "co_eff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have an array of model weights.\n",
    "\n",
    "Not very readable for us mere humans is it?!\n",
    "\n",
    "We will transfer the weights array to a Pandas DataFrame. The array order is in the same order of the list of features of X, so we will put that those into the DataFrame as well. And we will sort by influence in the model. Because both large negative and positive values are more influential in the model we will take the *absolute* value of the weight (ie remove any negative sign), and then sort by that absolute value. That will give us a more readable table of most influential features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_eff_df = pd.DataFrame() # create empty DataFrame\n",
    "co_eff_df['feature'] = list(X) # Get feature names from X\n",
    "co_eff_df['co_eff'] = co_eff\n",
    "co_eff_df['abs_co_eff'] = np.abs(co_eff)\n",
    "co_eff_df.sort_values(by='abs_co_eff', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the DataFrame.  What do you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>co_eff</th>\n",
       "      <th>abs_co_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>male</td>\n",
       "      <td>-1.327210</td>\n",
       "      <td>1.327210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>-0.733816</td>\n",
       "      <td>0.733816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CabinNumberImputed</td>\n",
       "      <td>-0.733485</td>\n",
       "      <td>0.733485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.606612</td>\n",
       "      <td>0.606612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>-0.462099</td>\n",
       "      <td>0.462099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AgeImputed</td>\n",
       "      <td>-0.210360</td>\n",
       "      <td>0.210360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CabinNumber</td>\n",
       "      <td>-0.206375</td>\n",
       "      <td>0.206375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>-0.153591</td>\n",
       "      <td>0.153591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.138774</td>\n",
       "      <td>0.138774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CabinLetter_T</td>\n",
       "      <td>-0.137296</td>\n",
       "      <td>0.137296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CabinLetter_A</td>\n",
       "      <td>-0.095199</td>\n",
       "      <td>0.095199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CabinLetter_G</td>\n",
       "      <td>-0.093240</td>\n",
       "      <td>0.093240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CabinLetterImputed</td>\n",
       "      <td>0.081020</td>\n",
       "      <td>0.081020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CabinLetter_missing</td>\n",
       "      <td>0.081020</td>\n",
       "      <td>0.081020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EmbarkedImputed</td>\n",
       "      <td>0.074070</td>\n",
       "      <td>0.074070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Embarked_missing</td>\n",
       "      <td>0.074070</td>\n",
       "      <td>0.074070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CabinLetter_C</td>\n",
       "      <td>-0.073198</td>\n",
       "      <td>0.073198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.071343</td>\n",
       "      <td>0.071343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CabinLetter_E</td>\n",
       "      <td>0.068965</td>\n",
       "      <td>0.068965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CabinLetter_B</td>\n",
       "      <td>-0.046083</td>\n",
       "      <td>0.046083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parch</td>\n",
       "      <td>-0.039898</td>\n",
       "      <td>0.039898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CabinLetter_F</td>\n",
       "      <td>0.023474</td>\n",
       "      <td>0.023474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CabinLetter_D</td>\n",
       "      <td>0.018162</td>\n",
       "      <td>0.018162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.013227</td>\n",
       "      <td>0.013227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature    co_eff  abs_co_eff\n",
       "10                 male -1.327210    1.327210\n",
       "0                Pclass -0.733816    0.733816\n",
       "9    CabinNumberImputed -0.733485    0.733485\n",
       "1                   Age -0.606612    0.606612\n",
       "2                 SibSp -0.462099    0.462099\n",
       "5            AgeImputed -0.210360    0.210360\n",
       "8           CabinNumber -0.206375    0.206375\n",
       "13           Embarked_S -0.153591    0.153591\n",
       "12           Embarked_Q  0.138774    0.138774\n",
       "22        CabinLetter_T -0.137296    0.137296\n",
       "15        CabinLetter_A -0.095199    0.095199\n",
       "21        CabinLetter_G -0.093240    0.093240\n",
       "7    CabinLetterImputed  0.081020    0.081020\n",
       "23  CabinLetter_missing  0.081020    0.081020\n",
       "6       EmbarkedImputed  0.074070    0.074070\n",
       "14     Embarked_missing  0.074070    0.074070\n",
       "17        CabinLetter_C -0.073198    0.073198\n",
       "11           Embarked_C  0.071343    0.071343\n",
       "19        CabinLetter_E  0.068965    0.068965\n",
       "16        CabinLetter_B -0.046083    0.046083\n",
       "3                 Parch -0.039898    0.039898\n",
       "20        CabinLetter_F  0.023474    0.023474\n",
       "18        CabinLetter_D  0.018162    0.018162\n",
       "4                  Fare  0.013227    0.013227"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_eff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now - the actual order of features, and the weights for each, will be different each time you fit the model, as it's random and we haven't put in place any controls.  So don't worry if yours differs a bit.  But, you'll likely find that amongst the top weighted features are :\n",
    "\n",
    "* male (being male reduces probability of survival)\n",
    "* Pclass (lower class passengers, who have a higher class number, reduces probability of survival)\n",
    "* age (being older reduces probability of survival)\n",
    "* CabinNumberImputed (cabin number is missing, which may mean they didn't have a cabin - likely lower class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show predicted probabilities\n",
    "\n",
    "The predicted probabilities are for the two alternative classes 0 (does not survive) or 1 (survive).\n",
    "\n",
    "Ordinarily we do not see these probabilities - the `predict` method used above applies a cut-off of 0.5 to classify passengers into survived or not, but we can see the individual probabilities for each passenger if desired.\n",
    "\n",
    "In a later example we will see how we can use such probabilities to adjust the sensitivity of our model to detecting survivors or non-survivors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each passenger has two values. These are the probability of not surviving (first value) or surviving (second value). Because we only have two possible classes we only need to look at one. Multiple values are important when there are more than one class being predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first ten predicted classes\n",
    "classes = model.predict(X_test_std)\n",
    "classes[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66867205, 0.33132795],\n",
       "       [0.76010224, 0.23989776],\n",
       "       [0.89602884, 0.10397116],\n",
       "       [0.89378926, 0.10621074],\n",
       "       [0.28465839, 0.71534161],\n",
       "       [0.87829479, 0.12170521],\n",
       "       [0.11232084, 0.88767916],\n",
       "       [0.93455564, 0.06544436],\n",
       "       [0.15062997, 0.84937003],\n",
       "       [0.54132821, 0.45867179]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first ten predicted probabilities \n",
    "# (note how the values relate to the classes predicted above)\n",
    "probabilities = model.predict_proba(X_test_std)\n",
    "probabilities[0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
